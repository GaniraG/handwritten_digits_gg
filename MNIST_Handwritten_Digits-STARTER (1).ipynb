{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Build a neural network of my own design to evaluate the MNIST dataset.\n",
    "\n",
    "Some of the benchmark results on MNIST include can be found [on Yann LeCun's page](https://webcache.googleusercontent.com/search?q=cache:stAVPik6onEJ:yann.lecun.com/exdb/mnist) and include:\n",
    "\n",
    "88% [Lecun et al., 1998](https://hal.science/hal-03926082/document)\n",
    "\n",
    "95.3% [Lecun et al., 1998](https://hal.science/hal-03926082v1/document)\n",
    "\n",
    "99.65% [Ciresan et al., 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)\n",
    "\n",
    "\n",
    "MNIST is a great dataset for sanity checking your models, since the accuracy levels achieved by large convolutional neural networks and small linear models are both quite high. This makes it important to be familiar with the data.\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update the PATH to include the user installation directory. \n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/root/.local/bin\"\n",
    "\n",
    "# Restart the Kernel before you move on to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important: Restart the Kernel before you move on to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python-headless==4.5.3.56\n",
      "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.1 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib==3.4.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (3.4.3)\n",
      "Requirement already satisfied: numpy==1.21.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.21.2)\n",
      "Requirement already satisfied: pillow==7.0.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (7.0.0)\n",
      "Collecting bokeh==2.1.1\n",
      "  Downloading bokeh-2.1.1.tar.gz (19.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.3 MB 61.1 MB/s eta 0:00:01     |███████████████████▏            | 11.6 MB 61.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch==1.11.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (1.11.0)\n",
      "Collecting torchvision==0.12.0\n",
      "  Downloading torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 54.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm==4.63.0\n",
      "  Downloading tqdm-4.63.0-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 7.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting ipywidgets==7.7.0\n",
      "  Downloading ipywidgets-7.7.0-py2.py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 33.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting livelossplot==0.5.4\n",
      "  Downloading livelossplot-0.5.4-py3-none-any.whl (22 kB)\n",
      "Collecting pytest==7.1.1\n",
      "  Downloading pytest-7.1.1-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 71.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==1.3.5\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 68.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seaborn==0.11.2\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[K     |████████████████████████████████| 292 kB 71.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter==1.0.0\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting ipykernel==4.10.0\n",
      "  Downloading ipykernel-4.10.0-py3-none-any.whl (109 kB)\n",
      "\u001b[K     |████████████████████████████████| 109 kB 66.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 2)) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (5.3)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (2.11.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (20.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (3.7.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0->-r requirements.txt (line 7)) (2.23.0)\n",
      "Collecting widgetsnbextension~=3.6.0\n",
      "  Downloading widgetsnbextension-3.6.10-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 60.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.7.0->-r requirements.txt (line 9)) (7.13.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.7.0->-r requirements.txt (line 9)) (5.0.4)\n",
      "Collecting jupyterlab-widgets>=1.0.0; python_version >= \"3.6\"\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "\u001b[K     |████████████████████████████████| 214 kB 59.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.7.0->-r requirements.txt (line 9)) (4.3.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.2.0)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest==7.1.1->-r requirements.txt (line 11)) (19.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from pytest==7.1.1->-r requirements.txt (line 11)) (1.5.0)\n",
      "Collecting tomli>=1.0.0\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.2.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas==1.3.5->-r requirements.txt (line 12)) (2019.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.7/site-packages (from seaborn==0.11.2->-r requirements.txt (line 13)) (1.7.1)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.4.4-py3-none-any.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 55.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 14)) (5.6.1)\n",
      "Collecting jupyter-console\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 14)) (5.7.4)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel==4.10.0->-r requirements.txt (line 15)) (6.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib==3.4.3->-r requirements.txt (line 2)) (45.2.0.post20200209)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib==3.4.3->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.7->bokeh==2.1.1->-r requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 7)) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 7)) (1.25.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 7)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 7)) (2019.11.28)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (3.0.3)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (2.5.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (4.4.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.16.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.1.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets==7.7.0->-r requirements.txt (line 9)) (4.6.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets==7.7.0->-r requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest==7.1.1->-r requirements.txt (line 11)) (3.0.0)\n",
      "Collecting qtpy>=2.4.0\n",
      "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 2.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyzmq>=17.1 in /opt/conda/lib/python3.7/site-packages (from qtconsole->jupyter==1.0.0->-r requirements.txt (line 14)) (19.0.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.6.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (3.1.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (1.4.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.4.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.3)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 14)) (0.8.3)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 14)) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 14)) (0.7.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.1.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.6.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.15.7)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.5.1)\n",
      "Building wheels for collected packages: bokeh\n",
      "  Building wheel for bokeh (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bokeh: filename=bokeh-2.1.1-py3-none-any.whl size=9257186 sha256=452f3588ec0d80d638c545ed005d637554c95ebeeeb5d71d711ff28fa5e8d4c6\n",
      "  Stored in directory: /root/.cache/pip/wheels/f7/55/ff/f3d7554e69382d31cf7ad857cf518af9b923134fca7d925187\n",
      "Successfully built bokeh\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement ipykernel>=6.14, but you'll have ipykernel 4.10.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement jupyter-client>=7.0.0, but you'll have jupyter-client 6.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement jupyter-core!=5.0.*,>=4.12, but you'll have jupyter-core 4.6.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement prompt-toolkit>=3.0.30, but you'll have prompt-toolkit 3.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement traitlets>=5.4, but you'll have traitlets 4.3.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: opencv-python-headless, bokeh, torchvision, tqdm, widgetsnbextension, ipykernel, jupyterlab-widgets, ipywidgets, livelossplot, iniconfig, py, tomli, pluggy, pytest, pandas, seaborn, qtpy, qtconsole, jupyter-console, jupyter\n",
      "\u001b[33m  WARNING: The script bokeh is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts py.test and pytest are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script qtpy is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script jupyter-console is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed bokeh-2.1.1 iniconfig-2.0.0 ipykernel-4.10.0 ipywidgets-7.7.0 jupyter-1.0.0 jupyter-console-6.6.3 jupyterlab-widgets-3.0.13 livelossplot-0.5.4 opencv-python-headless-4.5.3.56 pandas-1.3.5 pluggy-1.2.0 py-1.11.0 pytest-7.1.1 qtconsole-5.4.4 qtpy-2.4.1 seaborn-0.11.2 tomli-2.0.1 torchvision-0.12.0 tqdm-4.63.0 widgetsnbextension-3.6.10\n"
     ]
    }
   ],
   "source": [
    "# Install requirements\n",
    "!python -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataLoader in module torch.utils.data.dataloader:\n",
      "\n",
      "class DataLoader(typing.Generic)\n",
      " |  DataLoader(*args, **kwds)\n",
      " |  \n",
      " |  Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
      " |  the given dataset.\n",
      " |  \n",
      " |  The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      " |  iterable-style datasets with single- or multi-process loading, customizing\n",
      " |  loading order and optional automatic batching (collation) and memory pinning.\n",
      " |  \n",
      " |  See :py:mod:`torch.utils.data` documentation page for more details.\n",
      " |  \n",
      " |  Args:\n",
      " |      dataset (Dataset): dataset from which to load the data.\n",
      " |      batch_size (int, optional): how many samples per batch to load\n",
      " |          (default: ``1``).\n",
      " |      shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      " |          at every epoch (default: ``False``).\n",
      " |      sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      " |          samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      " |          implemented. If specified, :attr:`shuffle` must not be specified.\n",
      " |      batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      " |          returns a batch of indices at a time. Mutually exclusive with\n",
      " |          :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      " |          and :attr:`drop_last`.\n",
      " |      num_workers (int, optional): how many subprocesses to use for data\n",
      " |          loading. ``0`` means that the data will be loaded in the main process.\n",
      " |          (default: ``0``)\n",
      " |      collate_fn (callable, optional): merges a list of samples to form a\n",
      " |          mini-batch of Tensor(s).  Used when using batched loading from a\n",
      " |          map-style dataset.\n",
      " |      pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      " |          into CUDA pinned memory before returning them.  If your data elements\n",
      " |          are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      " |          see the example below.\n",
      " |      drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      " |          if the dataset size is not divisible by the batch size. If ``False`` and\n",
      " |          the size of dataset is not divisible by the batch size, then the last batch\n",
      " |          will be smaller. (default: ``False``)\n",
      " |      timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      " |          from workers. Should always be non-negative. (default: ``0``)\n",
      " |      worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
      " |          worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      " |          input, after seeding and before data loading. (default: ``None``)\n",
      " |      generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      " |          by RandomSampler to generate random indexes and multiprocessing to generate\n",
      " |          `base_seed` for workers. (default: ``None``)\n",
      " |      prefetch_factor (int, optional, keyword-only arg): Number of samples loaded\n",
      " |          in advance by each worker. ``2`` means there will be a total of\n",
      " |          2 * num_workers samples prefetched across all workers. (default: ``2``)\n",
      " |      persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
      " |          the worker processes after a dataset has been consumed once. This allows to\n",
      " |          maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      " |  \n",
      " |  \n",
      " |  .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      " |               cannot be an unpicklable object, e.g., a lambda function. See\n",
      " |               :ref:`multiprocessing-best-practices` on more details related\n",
      " |               to multiprocessing in PyTorch.\n",
      " |  \n",
      " |  .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      " |               When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      " |               it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      " |               rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      " |               configurations. This represents the best guess PyTorch can make because PyTorch\n",
      " |               trusts user :attr:`dataset` code in correctly handling multi-process\n",
      " |               loading to avoid duplicate data.\n",
      " |  \n",
      " |               However, if sharding results in multiple workers having incomplete last batches,\n",
      " |               this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      " |               be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      " |               dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      " |               cases in general.\n",
      " |  \n",
      " |               See `Dataset Types`_ for more details on these two types of datasets and how\n",
      " |               :class:`~torch.utils.data.IterableDataset` interacts with\n",
      " |               `Multi-process data loading`_.\n",
      " |  \n",
      " |  .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      " |               :ref:`data-loading-randomness` notes for random seed related questions.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataLoader\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Union[int, NoneType] = 1, shuffle: bool = False, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[Sequence], Iterable[Sequence], NoneType] = None, num_workers: int = 0, collate_fn: Union[Callable[[List[~T]], Any], NoneType] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Union[Callable[[int], NoneType], NoneType] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: int = 2, persistent_workers: bool = False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self) -> '_BaseDataLoaderIter'\n",
      " |      # We quote '_BaseDataLoaderIter' since it isn't defined yet and the definition can't be moved up\n",
      " |      # since '_BaseDataLoaderIter' references 'DataLoader'.\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |  \n",
      " |  __setattr__(self, attr, val)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  check_worker_number_rationality(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  multiprocessing_context\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_iterator': typing.Union[ForwardRef('_BaseDataLoad...\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  __parameters__ = (+T_co,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwds)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': 'torch.utils.data.dataloader',\n",
       "              '__annotations__': {'dataset': torch.utils.data.dataset.Dataset[+T_co],\n",
       "               'batch_size': typing.Union[int, NoneType],\n",
       "               'num_workers': int,\n",
       "               'pin_memory': bool,\n",
       "               'drop_last': bool,\n",
       "               'timeout': float,\n",
       "               'sampler': typing.Union[torch.utils.data.sampler.Sampler, typing.Iterable],\n",
       "               'prefetch_factor': int,\n",
       "               '_iterator': typing.Union[ForwardRef('_BaseDataLoaderIter'), NoneType]},\n",
       "              '__doc__': '\\n    Data loader. Combines a dataset and a sampler, and provides an iterable over\\n    the given dataset.\\n\\n    The :class:`~torch.utils.data.DataLoader` supports both map-style and\\n    iterable-style datasets with single- or multi-process loading, customizing\\n    loading order and optional automatic batching (collation) and memory pinning.\\n\\n    See :py:mod:`torch.utils.data` documentation page for more details.\\n\\n    Args:\\n        dataset (Dataset): dataset from which to load the data.\\n        batch_size (int, optional): how many samples per batch to load\\n            (default: ``1``).\\n        shuffle (bool, optional): set to ``True`` to have the data reshuffled\\n            at every epoch (default: ``False``).\\n        sampler (Sampler or Iterable, optional): defines the strategy to draw\\n            samples from the dataset. Can be any ``Iterable`` with ``__len__``\\n            implemented. If specified, :attr:`shuffle` must not be specified.\\n        batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\\n            returns a batch of indices at a time. Mutually exclusive with\\n            :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\\n            and :attr:`drop_last`.\\n        num_workers (int, optional): how many subprocesses to use for data\\n            loading. ``0`` means that the data will be loaded in the main process.\\n            (default: ``0``)\\n        collate_fn (callable, optional): merges a list of samples to form a\\n            mini-batch of Tensor(s).  Used when using batched loading from a\\n            map-style dataset.\\n        pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\\n            into CUDA pinned memory before returning them.  If your data elements\\n            are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\\n            see the example below.\\n        drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\\n            if the dataset size is not divisible by the batch size. If ``False`` and\\n            the size of dataset is not divisible by the batch size, then the last batch\\n            will be smaller. (default: ``False``)\\n        timeout (numeric, optional): if positive, the timeout value for collecting a batch\\n            from workers. Should always be non-negative. (default: ``0``)\\n        worker_init_fn (callable, optional): If not ``None``, this will be called on each\\n            worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\\n            input, after seeding and before data loading. (default: ``None``)\\n        generator (torch.Generator, optional): If not ``None``, this RNG will be used\\n            by RandomSampler to generate random indexes and multiprocessing to generate\\n            `base_seed` for workers. (default: ``None``)\\n        prefetch_factor (int, optional, keyword-only arg): Number of samples loaded\\n            in advance by each worker. ``2`` means there will be a total of\\n            2 * num_workers samples prefetched across all workers. (default: ``2``)\\n        persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\\n            the worker processes after a dataset has been consumed once. This allows to\\n            maintain the workers `Dataset` instances alive. (default: ``False``)\\n\\n\\n    .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\\n                 cannot be an unpicklable object, e.g., a lambda function. See\\n                 :ref:`multiprocessing-best-practices` on more details related\\n                 to multiprocessing in PyTorch.\\n\\n    .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\\n                 When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\\n                 it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\\n                 rounding depending on :attr:`drop_last`, regardless of multi-process loading\\n                 configurations. This represents the best guess PyTorch can make because PyTorch\\n                 trusts user :attr:`dataset` code in correctly handling multi-process\\n                 loading to avoid duplicate data.\\n\\n                 However, if sharding results in multiple workers having incomplete last batches,\\n                 this estimate can still be inaccurate, because (1) an otherwise complete batch can\\n                 be broken into multiple ones and (2) more than one batch worth of samples can be\\n                 dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\\n                 cases in general.\\n\\n                 See `Dataset Types`_ for more details on these two types of datasets and how\\n                 :class:`~torch.utils.data.IterableDataset` interacts with\\n                 `Multi-process data loading`_.\\n\\n    .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\\n                 :ref:`data-loading-randomness` notes for random seed related questions.\\n    ',\n",
       "              '_DataLoader__initialized': False,\n",
       "              '__init__': <function torch.utils.data.dataloader.DataLoader.__init__(self, dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Union[int, NoneType] = 1, shuffle: bool = False, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[Sequence], Iterable[Sequence], NoneType] = None, num_workers: int = 0, collate_fn: Union[Callable[[List[~T]], Any], NoneType] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Union[Callable[[int], NoneType], NoneType] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: int = 2, persistent_workers: bool = False)>,\n",
       "              '_get_iterator': <function torch.utils.data.dataloader.DataLoader._get_iterator(self) -> '_BaseDataLoaderIter'>,\n",
       "              'multiprocessing_context': <property at 0x7d7f7b942f50>,\n",
       "              '__setattr__': <function torch.utils.data.dataloader.DataLoader.__setattr__(self, attr, val)>,\n",
       "              '__iter__': <function torch.utils.data.dataloader.DataLoader.__iter__(self) -> '_BaseDataLoaderIter'>,\n",
       "              '_auto_collation': <property at 0x7d7f7b942ef0>,\n",
       "              '_index_sampler': <property at 0x7d7f7b942fb0>,\n",
       "              '__len__': <function torch.utils.data.dataloader.DataLoader.__len__(self) -> int>,\n",
       "              'check_worker_number_rationality': <function torch.utils.data.dataloader.DataLoader.check_worker_number_rationality(self)>,\n",
       "              '__orig_bases__': (typing.Generic[+T_co],),\n",
       "              '__dict__': <attribute '__dict__' of 'DataLoader' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'DataLoader' objects>,\n",
       "              '__parameters__': (+T_co,)})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataLoader.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#seeds for reproducibility\n",
    "seed = 3\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Specify your transforms as a list if you intend to .\n",
    "The transforms module is already loaded as `transforms`.\n",
    "\n",
    "MNIST is fortunately included in the torchvision module.\n",
    "Then, you can create your dataset using the `MNIST` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/vision/stable/datasets.html#mnist)).\n",
    "Make sure to specify `download=True`! \n",
    "\n",
    "Once your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create training set and define training dataloader\n",
    "training_data = datasets.MNIST(root=\"MNIST\", train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(training_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# Create test set and define test dataloader\n",
    "test_data = datasets.MNIST(root=\"MNIST\", train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split sizes (e.g., 90% train, 10% validation)\n",
    "train_size = int(0.9 * len(training_data))\n",
    "val_size = len(training_data) - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justify your preprocessing\n",
    "\n",
    "In your own words, why did you choose the transforms you chose? If you didn't use any preprocessing steps, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform image data (MNIST) to tensors as pytorch models cant work with image or ndarray if it is not converted to a tensor format. Scaled pixel values to [0, 1]\n",
    "* Normalise to help the model train more efficiently by standardizing the input values - used these paremeters (0.5,), (0.5,) as the images are grayscale so brightness (intensity of values) is used rather than color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset\n",
    "Using matplotlib, numpy, and torch, explore the dimensions of your data.\n",
    "\n",
    "You can view images using the `show5` function defined below – it takes a data loader as an argument.\n",
    "Remember that normalized images will look really weird to you! You may want to try changing your transforms to view images.\n",
    "Typically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.\n",
    "If `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## This cell contains a function for showing 5 images from a dataloader\n",
    "def show5(img_loader):\n",
    "    dataiter = iter(img_loader)\n",
    "    \n",
    "    batch = next(dataiter)\n",
    "    labels = batch[1][0:5]\n",
    "    images = batch[0][0:5]\n",
    "    for i in range(5):\n",
    "        print(int(labels[i].detach()))\n",
    "    \n",
    "        image = images[i].numpy()\n",
    "        plt.imshow(image.T.squeeze().T)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore data\n",
    "show5(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your Neural Network\n",
    "Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\n",
    "Use any architecture you like. \n",
    "\n",
    "*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the class for your neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = F.relu\n",
    "        self.fc1 = nn.Linear(28 * 28 * 1, 120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "net = Net()\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a loss function and an optimizer, and instantiate the model.\n",
    "\n",
    "If you use a less common loss function, please note why you chose that loss function in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose an optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# Choose a loss function\n",
    "# used CrossEntropyLoss as it is good one for multi class classification tasks\n",
    "# we wont need to apply Softmax as it is already incorporated to this loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running your Neural Network\n",
    "Use whatever method you like to train your neural network, and ensure you record the average loss at each epoch. \n",
    "Don't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!\n",
    "\n",
    "If you want to print your loss **during** each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training accuracy: 66.28% training loss: 1.35907\n",
      "Epoch 2 training accuracy: 86.48% training loss: 0.47847\n",
      "Epoch 3 training accuracy: 89.31% training loss: 0.37087\n",
      "Epoch 4 training accuracy: 90.34% training loss: 0.33207\n",
      "Epoch 5 training accuracy: 90.92% training loss: 0.30932\n",
      "Epoch 6 training accuracy: 91.45% training loss: 0.29178\n",
      "Epoch 7 training accuracy: 91.86% training loss: 0.27734\n",
      "Epoch 8 training accuracy: 92.35% training loss: 0.26414\n",
      "Epoch 9 training accuracy: 92.63% training loss: 0.25143\n",
      "Epoch 10 training accuracy: 93.02% training loss: 0.23913\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "# Establish a list for our history\n",
    "train_loss_history = list()\n",
    "val_loss_history = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Pass to GPU if available.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1} training accuracy: {train_correct/len(train_loader):.2f}% training loss: {train_loss/len(train_loader):.5f}')\n",
    "    train_loss_history.append(train_loss/len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss (and validation loss/accuracy, if recorded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss history\n",
    "plt.plot(train_loss_history, label=\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your model\n",
    "Using the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction. \n",
    "\n",
    "If your accuracy is over 90%, great work, but see if you can push a bit further! \n",
    "If your accuracy is under 90%, you'll need to make improvements.\n",
    "Go back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 93.33%\n",
      "Test loss: 0.22860\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "net.eval()  # Set the model to evaluation mode for testing\n",
    "\n",
    "# No need for gradient calculations during testing\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # Calculate the test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get the predicted class with highest score\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Calculate test accuracy\n",
    "        test_correct += (preds == labels).sum().item()\n",
    "\n",
    "# Calculate final test loss and accuracy\n",
    "test_accuracy = 100 * test_correct / len(test_loader.dataset)\n",
    "test_loss = test_loss / len(test_loader)\n",
    "\n",
    "# Print final test results\n",
    "print(f'\\nTest accuracy: {test_accuracy:.2f}%')\n",
    "print(f'Test loss: {test_loss:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving your model\n",
    "\n",
    "Once your model is done training, try tweaking your hyperparameters and training again below to improve your accuracy on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose an optimizer\n",
    "# Added momentum to solve the local minimum problem if there is any and weight_decay\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, weight_decay=0.001, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training accuracy: 93.36% training loss: 0.22834\n",
      "Epoch 2 training accuracy: 94.01% training loss: 0.20727\n",
      "Epoch 3 training accuracy: 94.47% training loss: 0.18945\n",
      "Epoch 4 training accuracy: 94.94% training loss: 0.17392\n",
      "Epoch 5 training accuracy: 95.40% training loss: 0.15976\n",
      "Epoch 6 training accuracy: 95.75% training loss: 0.14868\n",
      "Epoch 7 training accuracy: 95.98% training loss: 0.13844\n",
      "Epoch 8 training accuracy: 96.32% training loss: 0.12935\n",
      "Epoch 9 training accuracy: 96.50% training loss: 0.12140\n",
      "Epoch 10 training accuracy: 96.73% training loss: 0.11420\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "# Establish a list for our history\n",
    "train_loss_history = list()\n",
    "val_loss_history = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Pass to GPU if available.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1} training accuracy: {train_correct/len(train_loader):.2f}% training loss: {train_loss/len(train_loader):.5f}')\n",
    "    train_loss_history.append(train_loss/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 96.26%\n",
      "Test loss: 0.12652\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "net.eval()  # Set the model to evaluation mode for testing\n",
    "\n",
    "# No need for gradient calculations during testing\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # Calculate the test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get the predicted class with highest score\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Calculate test accuracy\n",
    "        test_correct += (preds == labels).sum().item()\n",
    "\n",
    "# Calculate final test loss and accuracy\n",
    "test_accuracy = 100 * test_correct / len(test_loader.dataset)\n",
    "test_loss = test_loss / len(test_loader)\n",
    "\n",
    "# Print final test results\n",
    "print(f'\\nTest accuracy: {test_accuracy:.2f}%')\n",
    "print(f'Test loss: {test_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class for your neural network\n",
    "# Added dropout layer for regularisation to improve accuracy but also remove overfitting if there is any\n",
    "# Added another hidden layer as well fc4\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = F.relu\n",
    "        self.fc1 = nn.Linear(28 * 28 * 1, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.dropout = nn.Dropout(0.5) #dropout layer\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "net = Net()\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose an optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, weight_decay=0.001, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training accuracy: 39.30% training loss: 1.75000\n",
      "Epoch 2 training accuracy: 77.51% training loss: 0.70508\n",
      "Epoch 3 training accuracy: 85.19% training loss: 0.49637\n",
      "Epoch 4 training accuracy: 87.82% training loss: 0.41167\n",
      "Epoch 5 training accuracy: 89.52% training loss: 0.35776\n",
      "Epoch 6 training accuracy: 90.66% training loss: 0.32280\n",
      "Epoch 7 training accuracy: 91.52% training loss: 0.29361\n",
      "Epoch 8 training accuracy: 92.24% training loss: 0.27238\n",
      "Epoch 9 training accuracy: 92.72% training loss: 0.25322\n",
      "Epoch 10 training accuracy: 93.14% training loss: 0.24047\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "# Establish a list for our history\n",
    "train_loss_history = list()\n",
    "val_loss_history = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Pass to GPU if available.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1} training accuracy: {train_correct/len(train_loader):.2f}% training loss: {train_loss/len(train_loader):.5f}')\n",
    "    train_loss_history.append(train_loss/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 95.53%\n",
      "Test loss: 0.14599\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "net.eval()  # Set the model to evaluation mode for testing\n",
    "\n",
    "# No need for gradient calculations during testing\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # Calculate the test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get the predicted class with highest score\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Calculate test accuracy\n",
    "        test_correct += (preds == labels).sum().item()\n",
    "\n",
    "# Calculate final test loss and accuracy\n",
    "test_accuracy = 100 * test_correct / len(test_loader.dataset)\n",
    "test_loss = test_loss / len(test_loader)\n",
    "\n",
    "# Print final test results\n",
    "print(f'\\nTest accuracy: {test_accuracy:.2f}%')\n",
    "print(f'Test loss: {test_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy dropped, probably overfitting is removed so might not be still bad idea to keep dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 9, 0, 1, 0, 7, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 7, 8, 9, 7, 8, 6, 4, 1,\n",
      "        9, 3, 8, 4, 4, 7, 0, 1, 9, 2, 8, 7, 8, 2, 6, 0, 6, 5, 3, 3, 9, 9, 1, 4,\n",
      "        0, 6, 1, 0, 0, 6, 2, 1, 1, 7, 7, 8, 4, 6, 0, 7, 0, 3, 6, 8, 7, 1, 3, 2,\n",
      "        4, 9, 4, 3, 6, 4, 1, 7, 2, 6, 6, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2,\n",
      "        3, 4, 5, 6], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your model\n",
    "Using `torch.save`, save your model for future loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(net, 'digits_recognition_gg.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
